{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fde608de",
   "metadata": {},
   "source": [
    "### TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f07c3144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, Model, regularizers\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Input, Flatten, MaxPooling2D, BatchNormalization, Dropout\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a73942a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n",
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7117ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = keras.utils.normalize(x_train, axis = 1)\n",
    "x_test = keras.utils.normalize(x_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36c3c7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.2797 - loss: 1.9720 - val_accuracy: 0.4476 - val_loss: 1.5420\n",
      "Epoch 2/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.4904 - loss: 1.4577 - val_accuracy: 0.5406 - val_loss: 1.3293\n",
      "Epoch 3/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.5482 - loss: 1.2986 - val_accuracy: 0.5706 - val_loss: 1.2403\n",
      "Epoch 4/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.5901 - loss: 1.1773 - val_accuracy: 0.5840 - val_loss: 1.2162\n",
      "Epoch 5/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6208 - loss: 1.1049 - val_accuracy: 0.6290 - val_loss: 1.0874\n",
      "Epoch 6/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.6415 - loss: 1.0374 - val_accuracy: 0.6402 - val_loss: 1.0657\n",
      "Epoch 7/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.6530 - loss: 1.0016 - val_accuracy: 0.6506 - val_loss: 1.0334\n",
      "Epoch 8/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.6694 - loss: 0.9579 - val_accuracy: 0.6492 - val_loss: 1.0343\n",
      "Epoch 9/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.6859 - loss: 0.9135 - val_accuracy: 0.6562 - val_loss: 1.0150\n",
      "Epoch 10/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.6931 - loss: 0.8857 - val_accuracy: 0.6534 - val_loss: 0.9980\n",
      "Epoch 11/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.7037 - loss: 0.8535 - val_accuracy: 0.6536 - val_loss: 1.0116\n",
      "Epoch 12/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7116 - loss: 0.8296 - val_accuracy: 0.6656 - val_loss: 0.9959\n",
      "Epoch 13/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 15ms/step - accuracy: 0.7226 - loss: 0.7947 - val_accuracy: 0.6732 - val_loss: 0.9575\n",
      "Epoch 14/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.7315 - loss: 0.7764 - val_accuracy: 0.6634 - val_loss: 1.0133\n",
      "Epoch 15/15\n",
      "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 14ms/step - accuracy: 0.7370 - loss: 0.7656 - val_accuracy: 0.6566 - val_loss: 1.0351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2a71ed450>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(Input(shape = (32, 32, 3)))\n",
    "model.add(Conv2D(32, 3, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Conv2D(64, 3, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "# model.add(Conv2D(128, 3, activation = 'relu'))\n",
    "model.add(Flatten())\n",
    "# model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(10, activation = 'softmax'))\n",
    "\n",
    "model.compile(\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    metrics = ['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size = 64, epochs = 15, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44d0add5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6526 - loss: 1.0418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.0643600225448608, 0.6485999822616577]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570c11c2",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f861095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632858e5",
   "metadata": {},
   "source": [
    "#### 1. Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a85409a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root = '../../data', \n",
    "                                           train = True, \n",
    "                                           transform = transform,\n",
    "                                           download = True\n",
    "                                          )\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root = '../../data', \n",
    "                                           train = False, \n",
    "                                           transform = transform,\n",
    "                                           download = True\n",
    "                                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e107cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_dataset, batch_size = 32, shuffle = True)\n",
    "test_loader = DataLoader(dataset = test_dataset, batch_size = 32, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca279a16",
   "metadata": {},
   "source": [
    "#### 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "419d556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv_1 = nn.Conv2d(3, 32, 3)\n",
    "        self.conv_2 = nn.Conv2d(32, 64, 3)\n",
    "        self.conv_3 = nn.Conv2d(64, 64, 3)\n",
    "        self.max_pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc_1 = nn.Linear(64 * 4 * 4, 64)\n",
    "        self.fc_2 = nn.Linear(64, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # input = N, 3, 32, 32\n",
    "        x = self.conv_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "#         print(x.shape)\n",
    "        x = self.conv_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        x = self.conv_3(x)\n",
    "        x = F.relu(x)\n",
    "#         x = self.max_pool(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc_1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6943eb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731758a2",
   "metadata": {},
   "source": [
    "#### 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdf91c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a811f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 0\n",
      "Epoch: 0, loss: 0.8430596401656353\n",
      "Starting epoch: 1\n",
      "Epoch: 1, loss: 0.7773111902858992\n",
      "Starting epoch: 2\n",
      "Epoch: 2, loss: 0.7306482018336835\n",
      "Starting epoch: 3\n",
      "Epoch: 3, loss: 0.6866341082525802\n",
      "Starting epoch: 4\n",
      "Epoch: 4, loss: 0.6453942098700688\n",
      "finished training\n"
     ]
    }
   ],
   "source": [
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(5):\n",
    "    print('Starting epoch:', epoch)\n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    print(f'Epoch: {epoch}, loss: {running_loss / n_total_steps}')\n",
    "print('finished training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7197455e",
   "metadata": {},
   "source": [
    "#### 4. Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_save_path = '../../model/cnn_cifar10.pth')\n",
    "torch.save(model.state_dict(), model_save_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b90d3a",
   "metadata": {},
   "source": [
    "#### 4. Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66953ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7169\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    samples = len(test_loader.dataset)\n",
    "    \n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(correct/samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c24842",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
